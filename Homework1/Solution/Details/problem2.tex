\textbf{Block Two: Feed-forward and back-propagation of the multi-task network (30 points)}
\begin{enumerate}
    \item[(i)] Finish the detailed \textbf{feed-forward computations} of a batch samples $(\bm{x}, y_a, y_b)$ 
    during a training iteration, coming with Ô¨Ånal predictions ($\hat{y}_a , \hat{y}_b$) of Task A, Task B. 
    \textbf{(10 points)}
    \item[(ii)] Use the back-propagation algorithm we have learned in class and give \textbf{the gradients 
    of the overall loss function with respect to the parameters at each layer} corresponding to 
    a batch of samples. \textbf{(20 points)}
\end{enumerate}